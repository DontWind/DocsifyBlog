# 1.OSI七层模型

![](https://pic1.zhimg.com/80/v2-2d62ba265be486cb94ab531912aa3b9c_720w.jpg)

**OSI模型各层的基本作用**

![](https://pic2.zhimg.com/80/v2-436927a69a3574532059a78623d3095d_720w.jpg)

# 2.HTTP

1. **HTTP 0.9/1.0**

   0.9版本只支持GET方法，不支持请求头

   1.0版本扩展了0.9版本：	

   - 在请求中加入了HTTP版本号，如：`GET /coolshell/index.heml HTML/1.0`
   - HTTP开始有header了，
   - 增加了HTTP Status Code 标识相关的状态码
   - 还有 `Content-Type`可以传输其它的文件了

2. **HTTP 1.1**

   解决了HTTP1.0的网络性能问题，以及增加了一些新的东西：

   - 可以设置 `keepalive`来让HTTP重用TCP链接，重用TCP链接可以节省每次请求都要在广域网上进行的TCP的三次握手的巨大开销，即“长连接”
   - 支持pipeline网络传输，只要第一个请求发出去了，不必等其回来，就可以发送第二个请求，可以减少整体的响应时间。（非幂等的POST方法或是有依赖的请求是不能被pipeline化的）
   - 支持 分片响应传输，在response时，不必说明Content-Length。客户端不能断开连接，直到收到客户端的EOF标识。这种技术又叫“服务端Push模型”，或是“服务端Push式的HTTP持久连接”
   - 增加了“cache control”机制
   - 增加了Language，Type，Language等header项
   - 主要增加了HOST头部字段，可以使服务器知道请求的是哪个网站。因为可以由多个域名解析到同一个IP上，要区分用户请求的是哪个域名，就需要在HTTP的协议中加入域名消息。

3. **HTTP 2.0**

4. **HTTP3.0**

# 3.HTTPS

1. **数字证书申请**：服务器的运营人员像数字证书认证机构提出证书认证申请，数字证书认证机构在判明申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个以签名的公开密钥，并将该公开密钥放入公钥证书绑定在一起。服务器将这份有数字认证机构颁发的公钥证书发送给客户端，以进行公开密钥加密方式通信。

2. **确认数据完整性**：

   1. 发送方从报文文本生成一个128位的散列值，发送方使用自己的私钥对这个摘要值进行加密来形成发送方的数字签名
   2. 发送方将数字签名作为报文的附件一起发送给接收方
   3. 报文的接收方首先从接收的原始报文中计算出128位散列值，再用发送方的公钥来对报文附加的数字签名进行解密。
   4. 如果两次得到的结果是一致的那么接收方可以确认该数字签名是发送方的，同时确认信息是真实的。

3. **中间人攻击**：

   1. 某网站有用于非对称加密的公钥A、私钥A’。
   2. 浏览器向网站服务器请求，服务器把公钥A明文给传输浏览器。
   3. 中间人劫持到公钥A，保存下来，把数据包中的公钥A替换成自己伪造的公钥B。（它当然也拥有对应的撕咬B‘）
   4. 浏览器生成一个用于对称加密的密钥X，用公钥B（浏览器无法得知公钥被替换了）加密后传给服务器
   5. 中间人劫持后用私钥B’解密得到密钥X，再用公钥A加密后传给服务器。
   6. 服务器拿到后用私钥A‘解密得到密钥X

   **根本原因是浏览器无法确认收到的公钥是不是网站自己的**

4. **证明浏览器收到的公钥是网站的公钥---数字证书**

   **数字证书**：包含网站A的信息，包括域名，公钥

   **如何防止数字证书被篡改**：

   

   ![](https://pic2.zhimg.com/80/v2-7c78935389af46e197e96d9cd91c06dd_720w.jpg)

   1. 数字签名制作过程：

      CA机构拥有非对称加密的私钥和公钥

      CA机构对证书明文数据T进行hash

      对hash后的值用私钥加密，得到数字签名S

   2. 浏览器验证过程：

      拿到证书，得到明文T，签名S

      用CA机构的公钥对S解密，得到S’（由于是浏览器信任的机构，所以浏览器保有它的公钥）

      用证书里指定的hash算法对明文T进行hash得到T’。

      若T'等于S'则表明证书可信，否则说明证书被篡改。

5. **能否篡改** 

   假设篡改了证书原文，但由于没有CA机构的私钥，所以无法等到此时加密后的签名，无法相应地篡改签名。浏览器收到该证书后会发现原文和签名解密后的值不一致，则说明证书已被篡改，证书不可信。

6. **能都掉包**：

   因为证书里包含了网站A的信息，包括域名，浏览器把证书里的域名与自己请求的域名比对一下就知道有没有被掉包了

7. **怎么证明CA机构的公钥是可信的**

   同样使用数字证书证明，操作系统、浏览器本身会预装一些它们信任的根证书，如果其中会有CA机构的根证书，这样就可以拿到它对应的可信公钥了

   实际上证书之间的认证也可以不止一层，可以A信任B，B信任C，以此类推，我们把它叫做`信任链`或`数字证书链`。也就是一连串的数字证书，由根证书为起点，透过层层信任，使终端实体证书的持有者可以获得转授的信任，以证明身份。

8. **每次进行HTTPS请求时都**必须**在SSL/TLS层进行握手传输密钥吗？**

   这也是我当时的困惑之一，显然每次请求都经历一次密钥传输过程非常耗时，那怎么达到只传输一次呢？

   服务器会为每个浏览器（或客户端软件）维护一个session ID，在TLS握手阶段传给浏览器，浏览器生成好密钥传给服务器后，服务器会把该密钥存到相应的session ID下，之后浏览器每次请求都会携带session ID，服务器会根据session ID找到相应的密钥并进行解密加密操作，这样就不必要每次重新制作、传输密钥了！

# 4.HTTP2.0

- **二进制分帧**

  http2.0之所以能够突破http1.x标准的性能限制，改进传输性能，实现低延迟和高吞吐量，就是因为其新增了二进制分帧层

  帧（Frame）包含部分：类型Type，长度length，标记Flags，流标识Stream和frame payload有效载荷

  消息（Message）：一个完整的请求或者响应，比如请求、响应等，由一个或多个Frame组成。

  流：连接中的一个虚拟信道，可以承载双向消息传输。每个流有唯一整数标识符。为了防止两端流ID冲突，客户端发起的流具有奇数ID，服务端发起的流具有偶数ID

  流标识是描述二进制frame的格式，使得每个frame能够基于http2发送，与流标识联系的是一个流，每个流是一个逻辑联系，一个独立的双向的frame存在于客户端和服务器端之间的http2连接中。一个http2连接上可包含多个并发打开的流，这个并发流的数量能够由客户端设置。

  在二进制分帧层上，http2.0会将所有传输信息分割为更小的消息和帧，并对它们采用二进制格式的编码将其封装，新增的二进制分帧层同时也能够保证http的各种动词，方法，首部都不受影响，兼容上一代http标准。首部信息header封装到Headers帧中，而request body将被封装到Data帧中。

  ![](https://user-gold-cdn.xitu.io/2019/10/31/16e208ee1d0caab8?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

- **多路复用/连接共享**

  在http1.1中，浏览器客户端在同一时间，针对同一域名下的请求有一定数量的限制，超过限制数目的请求会被阻塞。这也是为何一些站点会有多个静态资源CDN域名的原因之一。

  多路复用允许**同时**通过单一的http/2连接发起多重的请求-响应消息。有了新的分帧机制后，http2.0不再依赖多个TCP连接去实现多流并行了。每个数据流都拆分成很多互不依赖的帧，而这些帧可以交错（乱序发送），还可以分优先级，最后再在另一端把它们重新组合起来。

  http2.0的连接都是持久化的，而且客户端与服务器之间也需要一个连接即可。http2连接可以承载数十或数百个流的复用，多路复用意味着来自很多流的数据包能够混合在一起通过同一个连接传输。当到达终点时，再根据不同帧首部的流标识符重新连接将不同的数据流组装。

  ![](https://user-gold-cdn.xitu.io/2019/10/31/16e208ee1cebfa44?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

  上图展示了一个连接上的多个传输数据流：客户端向服务端传输数据帧stream5，同时服务端向客户端乱序发送stream1和stream3。这次连接上有三个响应请求乱序并行交换。、

- **头部压缩**

  http2.0使用encoder来减少需要传输的header大小，通讯双方各自缓存一份头部字段表，既避免了重复header的传输，又减小了需要传输的大小。

  对于相同的数据，不再通过每次请求和响应发送，通信期间几乎不会改变通用键-值对（用户代理、可接受的媒体类型等等）只需发送一次。

  如果请求中不包含首部，此时所有请求的首部都自动使用之前请求发送的首部。

  如果首部发生了变化，则只需要将变化的部分加入到header帧中，改变的部分会加入到头部字段表中，首部表在http2.0的连接存续期内始终存在，由客户端和服务器共同渐进地更新。

  常用的gzip等是报文内容（body）的压缩，http2.0用的是专门为首部压缩而设计的HPACK算法  

  - **压缩原理**：用header字段表里的索引代替实际的header。

    http 2.0的HPACK算法使用一份索引表来定义常用的http Header，把常用的http Header存放在表里，请求的时候便只需要发送在表里的索引位置即可。

    例如 :method=GET 使用索引值 2 表示，:path=/index.html 使用索引值 5 表示，如下图：

    ![](https://user-gold-cdn.xitu.io/2019/10/31/16e208ee3d18e3b3?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

    只要给服务端发送一个 Frame，该 Frame 的 Payload 部分存储 0x8285，Frame 的 Type 设置为 Header 类型，便可表示这个 Frame 属于 http Header，请求的内容是：

    ```
    1GET /index.html
    ```

    为什么是 0x8285，而不是 0x0205？这是因为高位设置为 1 表示这个字节是一个完全索引值（key 和 value 都在索引中）。

    类似的，通过高位的标志位可以区分出这个字节是属于一个完全索引值，还是仅索引了 key，还是 key和value 都没有索引。

    因为索引表的大小的是有限的，它仅保存了一些常用的 http Header，同时每次请求还可以在表的末尾动态追加新的 http Header 缓存，动态部分称之为 Dynamic Table。Static Table 和 Dynamic Table 在一起组合成了索引表。

    HPACK 不仅仅通过索引键值对来降低数据量，同时还会将字符串进行霍夫曼编码来压缩字符串大小。

    ```
    以常用的 User-Agent 为例，它在静态表中的索引值是 58，它的值是不存在表中的，因为它的值是多变的。第一次请求的时候它的 key 用 58 表示，表示这是一个 User-Agent ，它的值部分会进行霍夫曼编码（如果编码后的字符串变更长了，则不采用霍夫曼编码）。
    
    服务端收到请求后，会将这个 User-Agent 添加到 Dynamic Table 缓存起来，分配一个新的索引值。客户端下一次请求时，假设上次请求User-Agent的在表中的索引位置是 62， 此时只需要发送 0xBE（同样的，高位置 1），便可以代表：User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.146 Safari/537.36。
    ```

    ![](https://user-gold-cdn.xitu.io/2019/10/31/16e208ee50805e63?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

    最终，相同的 Header 只需要发送索引值，新的 Header 会重新加入 Dynamic Table

- **请求优先级**

  将http消息分为很多独立帧之后，就可以通过优化这些帧的交错和传输顺序进一步优化性能。每个流都可以带有一个31比特的优先值：0 表示最高优先级；2的31次方-1 表示最低优先级。

  服务器可以根据流的优先级，控制资源分配（CPU、内存、带宽），而在响应数据准备好之后，优先将最高优先级的帧发送给客户端。高优先级的流都应该优先发送，但又不会绝对的。绝对地准守，可能又会引入首队阻塞的问题：高优先级的请求慢导致阻塞其他资源交付。

  分配处理资源和客户端与服务器间的带宽，不同优先级的混合也是必须的。客户端会指定哪个流是最重要的，有一些依赖参数，这样一个流可以依赖另外一个流。优先级别可以在运行时动态改变，当用户滚动页面时，可以告诉浏览器哪个图像是最重要的，你也可以在一组流中进行优先筛选，能够突然抓住重点流。

  - 优先级最高：主要的HTML
  - 优先级高：CSS文件
  - 优先级中：JS文件
  - 优先级低：图片

- 服务端推送

  服务器可以对一个客户端请求发送多个响应，服务器向客户端推送资源无需客户端明确地请求。并且，服务端推送能把客户端所需要的资源随着index.html一起发送到客户端，省去了客户端重复请求的步骤。

  因为没有发起请求，建立连接操作，所以静态资源通过服务端推送的方式可以极大地提升速度。

  如果一个请求是由你的主页发起的，服务器很可能会响应主页内容、logo、以及样式表，因为服务器知道客户端会用到这些东西，这相当于在一个HTML文档内集合了所有的资源。

  服务器推送还有一个很大的优势：可以缓存，也让在遵循同源的情况下，不同页面之间可以共享缓存资源称为可能。

  ![](https://user-gold-cdn.xitu.io/2019/10/31/16e208ee5cbb8b0e?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

  注意点：

  - 推送遵循同源策略
  - 这种服务端的推送是基于客户端的请求响应来确定的

  当服务端需要主动推送某个资源时，便会发送一个`Frame Type ：PUSH_PROMISE`的Frame，里面携带了PUSH需要新建的Steam ID。意思是告诉客户端：接下来我要用这个ID向你发送东西，客户端准备好接收。客户端解析Frame时，发现它是一个PUSH_PROMISE类型，便会准备接收服务端要推送的流。

- http2.0性能瓶颈

  因为现在所有的压力集中在底层一个TCP连接之上，TCP很可能就是下一个性能瓶颈，因为TCP分组的队首阻塞问题，单个TCP packet丢失导致整个连接阻塞，无法逃避，此时所有消息都会受到影响。

# 5.HTTP3.0（QUIC）

1. **为什么选择UDP**

   - 基于TCP开发的设备和协议非常多，兼容困难
   - TCP协议栈是Linux内部的重要部分，修改和升级成本大
   - UDP本身是无连接的、没有建链和拆链成本
   - UDP的数据包无对头阻塞问题
   - UDP改造成本小

   > - QUIC协议最初由Google的Jim Roskind设计，实施并于2012年部署，在2013年随着实验的扩大而公开宣布，并向IETF进行了描述。
   > - QUIC提高了当前正在使用TCP的面向连接的Web应用程序的性能。它在两个端点之间使用用户数据报协议（UDP）建立多个复用连接来实现此目的。
   > - QUIC的次要目标包括减少连接和传输延迟，在每个方向进行带宽估计以避免拥塞。它还将拥塞控制算法移动到用户空间，而不是内核空间，此外使用前向纠错（FEC）进行扩展，以在出现错误时进一步提高性能。

   ![](https://img-blog.csdnimg.cn/20200922124129106.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dvbGZHdWlEYW8=,size_16,color_FFFFFF,t_70#pic_center)

## 1.QUIC详解

1. **队头阻塞问题**：

   `队头阻塞是计算机网络中一种性能受限的现象，通俗来说就是：一个数据包影响了一堆数据包，它不来大家都走不了`

   - 队头阻塞问题可能存在于HTTP层和TCP层，在HTTP1.X时两个层次都存在该问题。

   ![](https://img-blog.csdnimg.cn/20200922124452630.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dvbGZHdWlEYW8=,size_16,color_FFFFFF,t_70#pic_center)

   HTTP2.0的多路复用机制解决了HTTP层的队头阻塞问题，但是在TCP层仍然存在队头阻塞问题

   TCP协议在收到数据包之后，这部分数据可能是乱序到达的，但是TCP必须将所有数据收集排序整合后给上层使用，如果其中某个包丢失了，就必须等待重传，从而出现某个丢包数据阻塞整个连接的数据使用。

   多路复用是 HTTP2 最强大的特性 ，能够将多条请求在一条 TCP 连接上同时发出去。但也恶化了 TCP 的一个问题，队头阻塞 ，如下图示：![](https://img-blog.csdnimg.cn/20200922135620387.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dvbGZHdWlEYW8=,size_16,color_FFFFFF,t_70#pic_center)

   - HTTP2 在一个 TCP 连接上同时发送 4 个 Stream。其中 Stream1 已经正确到达，并被应用层读取。

   - 但是 Stream2 的第三个 tcp segment 丢失了，TCP 为了保证数据的可靠性，需要发送端重传第 3 个 segment 才能通知应用层读取接下去的数据，虽然这个时候 Stream3 和 Stream4 的全部数据已经到达了接收端，但都被阻塞住了。

   - 不仅如此，由于 HTTP2 强制使用 TLS，还存在一个 TLS 协议层面的队头阻塞![](https://img-blog.csdnimg.cn/20200922135807354.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dvbGZHdWlEYW8=,size_16,color_FFFFFF,t_70#pic_center)

   - QUIC多路复用和HTTP2类似。`在一条QUIC连接上可以并发发送多个HTTP请求（stream）`但是QUIC的多路复用相比HTTP2有一个很大的优势

     - QUIC 上的一个连接上的多个stream之间没有依赖。这样假如stream2丢了一个udp packet，也只会影响stream2的处理。不会影响stream2之前及之后的stream的处理。

       在很大程度上缓解甚至消除了队头阻塞的影响。

       QUIC协议是基于UDP协议实现的，`在一条链接上可以由多个流，流与流之间是互不影响的，当一个流出现丢包影响范围非常小，从而解决队头阻塞问题。`

2. **0RTT建链**

   RTT是衡量网络建链的常用指标，也就是数据包一来一回的时间消耗。

   ![](https://img-blog.csdnimg.cn/20200922124623833.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dvbGZHdWlEYW8=,size_16,color_FFFFFF,t_70#pic_center)

   `RTT包括三部分：往返传播时延、网络设备内排队时延、应用程序数据处理时延`

   ![](https://img-blog.csdnimg.cn/20200922124649743.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dvbGZHdWlEYW8=,size_16,color_FFFFFF,t_70#pic_center)

   一般来说HTTPS协议要建立完整链接包括：TCP握手和TLS握手，总计需要至少2-3个RTT，普通的HTTP协议也需要至少1个RTT才可以完成握手。然而QUIC协议可以实现在第一个包就可以包含有效地应用数据，从而实现0RTT，但这也是有条件的。

   什么是0RTT建链？（传输层0RTT就能建立连接，加密层0RTT就能建立加密连接）

   **QUIC的0RTT也是需要条件的额，对于第一次交互的客户端和服务端0RTT也是做不到的，毕竟双方完全的陌生,因此QUIC协议可以分为首次连接和非首次连接**

   1. 首次连接

      使用QUIC协议的客户端和服务端要使用1RTT进行密钥交换，使用的交换算法是DH算法

      首次连接过程：

      > 1. 客户端对于首次连接的服务端发送client hello请求
      > 2. 服务端生成一个素数p和一个整数g，同时生成一个私钥K~s_pri~为私钥，然后计算出公钥K~s_pub~=g^Ks_pri^ mod p，服务端将  K~s_pub~，p，g三个元素打包为config，后续发送给客户端。
      > 3. 客户端随机生成一个自己的私钥K~c_pri~，再从config中读取g和p，计算客户端公钥K~c_pub~=g^Kc_pri^ mod p。
      > 4. 客户端使用自己的私钥K~c_pri~和服务端发来的config中读取的服务端公钥K~s_pub~，生成后续数据加密用的密钥K=K~s_pub~^Kc_pri^ mod p。
      > 5. 客户端使用密钥K加密业务数据，并追加组件的公钥K~c_pub~，都传递给服务端。
      > 6. 服务端根据组件的私钥K~s_pri~和客户端公钥K~c_pub~生成客户端加密用的密钥K=K~c_pub~^Ks_pri^ mod p
      > 7. 为了保证数据安全，上述生成的密钥K只会生成使用一次，后续服务端会按照相同的规则生成一套全新的公钥和私钥，并使用这组公私钥生成新的密钥M。
      > 8. 服务端将新公钥和新密钥M加密的数据发给客户端，客户端根据新的服务端公钥和自己原来的私钥计算出本次的密钥M，进行解密。
      > 9. 之后的客户端和服务端数据交互都使用密钥M来完成，密钥K只使用一次。![](https://img-blog.csdnimg.cn/20200922125320566.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dvbGZHdWlEYW8=,size_16,color_FFFFFF,t_70#pic_center)

   2. 非首次连接

      前面提到客户端和服务端首次连接时服务端传递了config包，里面包含了服务端公钥和两个随机数，客户端会将config存储下来，后续再连接时可以直接使用，从而跳过这个1RTT，实现0RTT的业务数据交互。

      客户端保存config是有时间期限的，在config失效之后人仍然需要进行首次连接时的密钥交换。

3.  前向安全问题

   `前向安全指的是密钥泄露也不会让之前加密的数据被泄露，影响的只有当前，对之前的数据无影响。`

   **前面提到QUIC协议首次连接时先后生成了两个加密密钥，由于config被客户端存储了，如果期间服务端私钥K~s_pri~泄露，那么可以根据K=K~c_pub~^Ks_pri^ mod p 计算出密钥K**

   **如果一直使用这个密钥进行加解密，那么就可以用K解密素有历史消息，因此后续又生成了新密钥，使用其进行加密，当时完成交互时则销毁，从而实现了前向安全**

   ![](https://img-blog.csdnimg.cn/20200922125953787.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dvbGZHdWlEYW8=,size_16,color_FFFFFF,t_70#pic_center)

4. **前向纠错**

   前向纠错（也叫前向纠错码Forward Error Correction 简称FEC）是增加数据通讯可信度的方法。在单向通讯信道中，一旦错误被发现，其接收器将无权再请求传输。

   FEC是利用数据进行传输冗余消息的方法，当传输中出现错误，将允许接收器再建数据。

   > **QUIC实现**：Quic每发送一组数据就对这组数据进行异或运算，并将结果作为一个FEC包发送出去，接收方收到这一组数据后根据数据包和FEC包即可进行校验和纠错。

5. 连接迁移

   TCP协议使用五元组来表示一条唯一的连接，当我们从4G环境切换到wifi环境时，手机的IP地址就会发生变化，这时必须创建新的TCP连接才能继续传输数据

   **QUIC协议基于UDP实现摒弃了五元组的概念，使用64位的随机数作为连接的ID，并使用该ID表示连接。**

   基于QUIC协议之下，我们在日常wifi和4G切换时，或者不同基站之间切换都不会重连，从而提高业务层的体验

   ![](https://img-blog.csdnimg.cn/20200922130333415.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dvbGZHdWlEYW8=,size_16,color_FFFFFF,t_70#pic_center)
   
6. **改进的拥塞控制**

   QUIC协议当前默认使用了TCP协议的Cubic拥塞控制算法，同时也支持 CubicBytes, Reno, RenoBytes, BBR, PCC 等拥塞控制算法。

   **改进：**

   1. **可插拔：**能够非常灵活的生效，变更和停止

      `应用程序层面就能实现不同的拥塞控制算法，不需要操作系统，不需要内核支持`。因为传统的TCP拥塞控制，必须要端到端的网络协议栈支持，才能实现控制效果，而内核和操作系统的部署成本非常高，升级周期长，不利于产品的快速迭代。

      `应用程序不需要停机和升级就能实现拥塞控制的变更`，只需要服务端修改配置并重启，完全不需要停止服务就能实现拥塞控制的切换。STGW在配置层面进行了优化，我们可以针对不同业务，不同网络制式，甚至不同的RTT，使用不同的拥塞控制算法。

   2. **单调递增的Packet Number**

      - TCP为了保证可靠性，使用了基于字节序号的Sequence Number及ACK来确认消息的有序到达。

      - QUIC同样是一个可靠的协议，它使用Packet  Number代替了TCP的sequence Number，并且每个Packet Number都严格递增，也就是说就算Packet N丢失了，重传的Packet Number也比原来的值N大。![](https://img-blog.csdnimg.cn/20200922133727910.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dvbGZHdWlEYW8=,size_16,color_FFFFFF,t_70#pic_center)

      - TCP的重传缺点：如上图所示，无法确定响应是来自于原始请求还是重传请求。

      - ![](https://img-blog.csdnimg.cn/20200922133916874.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dvbGZHdWlEYW8=,size_16,color_FFFFFF,t_70#pic_center)

        QUIC应为Packet Number的严格递增可以轻易的分辨原始请求和重传请求的响应。但是单纯的严格递增的Packet Number肯定是无法保证数据的顺序性和可靠性。QUIC又引入了一个 Stream offset的概念。

        ![](https://img-blog.csdnimg.cn/20200922134146426.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dvbGZHdWlEYW8=,size_16,color_FFFFFF,t_70#pic_center)

        即一个Stream可以经过多个Packet传输，Packet Number严格递增没有依赖

        > Packet 里的 Payload 如果是 Stream 的话，就需要依靠 Stream 的 Offset
        > 来保证应用数据的顺序。
        > 如图所示，发送端先后发送了 Pakcet N 和 Pakcet N+1，Stream 的Offset 分别是 x 和 x+y。
        > 假设 Packet N 丢失了，发起重传，重传的 Packet Number 是 N+2，但是它的 Stream 的 Offset 依然是 x，这样就算 Packet N + 2 是后到的，依然可以将 Stream x 和 Stream x+y 按照顺序组织起来，交给应用程序处理。

      

   3. **不允许Reneging** ~（中途退出）~

      Reneging即接收方丢弃已经接收并且上报给SACK选项的内容。**`TCP 协议不鼓励这种行为，但是协议层面允许这样的行为。主要是考虑到服务器资源有限，比如 Buffer 溢出，内存不够等情况。`**

      Reneging对数据重传会产生很大的干扰。因为Sack都已经表明收到了，但是接收端事实上丢弃了该数据。

      QUIC 在协议层面禁止 Reneging，一个 Packet 只要被 Ack，就认为它一定被正确接收，减少了这种干扰。

   4. **更多的ACK块**

      TCP的Sack选项能够告诉发送方已经接收到的连续Segment的范围，方便发送方进行选择性重传。

      **由于TCP头部最大只有60个字节，标准头部占用了20字节，所以TCP Option最大长度只有40字节，再加上TCP TimeStamp Option占用了10个字节，所以留给Sack选项的只有30个字节。每一个SackBlock的长度是8字节，加上SackOption头部2个字节，也就意味着TCP Sack Option最大只能提供3个Block。**

      **`但是 QUIC ACK Frame可以同时提供256个 Ack Block，在丢包率比较高的网络下，更更多的Sack Block 可以提升网络的恢复速度，减少重传量。`**

   5. **ACK Delay：**

      TCP的Time Stamp选项没有计算接收端接收到Segment~（段，部分；）~到发送ACK该segment的事件。这个时间可以简称为ACK Delay。![](https://img-blog.csdnimg.cn/20200922134723577.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dvbGZHdWlEYW8=,size_16,color_FFFFFF,t_70#pic_center)

      - TCP的RTT计算方法![](https://img-blog.csdnimg.cn/20200922134807851.png#pic_center)
      - QUIC的RTT计算方法![](https://img-blog.csdnimg.cn/20200922134824234.png#pic_center)

   6. 基于Stream和connection级别的流量控制

      [基于 stream 和 connecton 级别的流量控制](https://blog.csdn.net/wolfGuiDao/article/details/108729560)

   7. 总结

      QUIC协议 存在的意义在于解决 TCP 协议的一些无法解决的痛点

      - 多次握手：TCP 协议需要三次握手建立连接，而如果需要 TLS 证书的交换，那么则需要更多次的握手才能建立可靠连接，这在如今长肥网络的趋势下是一个巨大的痛点
      - 队头阻塞：TCP 协议下，如果出现丢包，则一条连接将一直被阻塞等待该包的重传，即使后来的数据包可以被缓存，但也无法被递交给应用层去处理。
      - 无法判断一个 ACK 是重传包的 ACK 还是原本包的 ACK：比如 一个包 seq=1, 超时重传的包同样是 seq=1，这样在收到一个 ack=1 之后，我们无法判断这个 ack 是对之前的包的 ack 还是对重传包的 ack，这会导致我们对 RTT 的估计出现误差，无法提供更准确的拥塞控制
      - 无法进行连接迁移：一条连接由一个四元组标识，在当今移动互联网的时代，如果一台手机从一个 wifi 环境切换到另一个 wifi 环境，ip 发生变化，那么连接必须重新建立，inflight 的包全部丢失。

   
# 6.Websocket

1. **概述**

   Webscoket是Web浏览器和服务器之间的一种全双工通信协议，其中WebSocket协议由IETF定为标准，WebSocket API由W3C定为标准。一旦Web客户端与服务器建立起连接，之后的全部数据通信都通过这个连接进行。通信过程中，可互相发送JSON、XML、HTML或图片等任意格式的数据。

2. **与HTTP协议相比：**

   - 相同点：
     - 都是基于TCP的应用层协议
     - 都使用Request/Response模型进行连接的建立
     - 在连续的建立过程中对错误的处理方式相同，在这个阶段WS可能返回和HTTP相同的状态码。
     - 都可以在网络中传输数据
   - 不同点：
     - WS使用HTTP来建立连接，但是定义了一系列新的header域，这些域在HTTP中并不会使用
     - WS的连接不能通过中间人来转发，它必须是一个直接连接
     - WS连接建立后，通信双方可以在任何时刻向另一方发送数据
     - WS连接建立之后，数据的传输使用帧来传递，不再需要Request消息
     - WS的数据帧有序

3. **建立WS连接**

   ![](https://img-blog.csdnimg.cn/20200527233246458.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xMODQ1ODc2NDI1,size_16,color_FFFFFF,t_70)

   websocket是基于TCP的一个应用协议，与HTTP协议的关联之处在于websocket的握手数据被HTTP服务器当作HTTP包来处理，主要通过Update request HTTP包建立起连接，之后的通信全部使用websocket自己的协议。

   **请求：**TCP连接建立后，客户端发送Websocket的握手请求，请求报文头部如下：

   ```
   GET /uin=xxxxxxxx&app=xxxxxxxxx&token=XXXXXXXXXXXX HTTP/1.1
   Host: server.example.cn:443
   Connection: Upgrade
   Pragma: no-cache
   Cache-Control: no-cache
   User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36
   Upgrade: websocket
   Sec-WebSocket-Version: 13
   Accept-Encoding: gzip, deflate
   Accept-Language: zh-CN,zh;q=0.9
   Cookie: user_id=XXXXX
   Sec-WebSocket-Key: 1/2hTi/+eNURiekpNI4k5Q==
   Sec-WebSocket-Extensions: permessage-deflate; client_max_window_bits
   Sec-WebSocket-Protocol: binary, base64
   
   第一行为为请求的方法，类型必须为GET，协议版本号必须大于1.1
   Upgrade字段必须包含，值为websocket
   Connection字段必须包含，值为Upgrade
   Sec-WebSocket-Key字段必须包含 ，记录着握手过程中必不可少的键值。
   Sec-WebSocket-Protocol字段必须包含 ，记录着使用的子协议
   Origin（请求头）：Origin用来指明请求的来源，Origin头部主要用于保护Websocket服务器免受非授权的跨域脚本调用Websocket API的请求。也就是不想没被授权的跨域访问与服务器建立连接，服务器可以通过这个字段来判断来源的域并有选择的拒绝。
   ```

   **响应：**服务器接收到请求后，返回状态码为101 Switching Protocols 的响应。

   ```
   HTTP/1.1 101 Switching Protocols
   Server: WebSockify Python/2.6.6
   Date: Wed, 27 May 2020 03:03:21 GMT
   Upgrade: websocket
   Connection: Upgrade
   Sec-WebSocket-Accept: hXXXXXXXXXXXXXXxGmM=
   Sec-WebSocket-Protocol: binary
   
   Sec-WebSocket-Accept字段是由握手请求中的Sec-WebSocket-Key字段生层的。
   ```

   ![](https://img-blog.csdnimg.cn/20200527233345809.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xMODQ1ODc2NDI1,size_16,color_FFFFFF,t_70)

   ```
   FIN，指明Frame是否是一个Message里最后Frame（之前说过一个Message可能又多个Frame组成）；1bit，是否为信息的最后一帧
   RSV1-3，默认是0 (必须是0)，除非有扩展定义了非零值的意义。
   Opcode，这个比较重要，有如下取值是被协议定义的
   				0x00 denotes a continuation frame
   				0x01 表示一个text frame
   				0x02 表示一个binary frame
   				0x03 ~~ 0x07 are reserved for further non-control frames,为将来的非控制消息片段保留测操作码
   				0x08 表示连接关闭
   				0x09 表示 ping (心跳检测相关)
   				0x0a 表示 pong (心跳检测相关)
   				0x0b ~~ 0x0f are reserved for further control frames,为将来的控制消息片段保留的操作码
   Mask，这个是指明“payload data”是否被计算掩码。这个和后面的Masking-key有关，如果设置为1,掩码键必须放在masking-key区域，客户端发送给服务端的所有消息，此位的值都是1；
   Payload len，数据的长度，
   Masking-key，0或者4bit，只有当MASK设置为1时才有效。，给一个Websocket中掩码的意义
   Payload data，帧真正要发送的数据，可以是任意长度，但尽管理论上帧的大小没有限制，但发送的数据不能太大，否则会导致无法高效利用网络带宽，正如上面所说Websocket提供分片。
   Extension data：扩展数据，如果客户端和服务端没有特殊的约定，那么扩展数据长度始终为0
   Application data：应用数据，
   ```

   [阮一峰-Websocket](http://www.ruanyifeng.com/blog/2017/05/websocket.html) [Websocket使用配置](http://www.javashuo.com/article/p-rqpvtobu-ev.html)  [Websocket心跳、重连](http://www.javashuo.com/article/p-zzfkhypo-he.html)   [Websocket离线消息](https://blog.csdn.net/baicaim/article/details/109075038)

​     

​    

   
